{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the following libraries\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Load Dataset\n",
    "We will be using the MNIST dataset which contains photos of handwritten digits. Keras already comes with this dataset, so we can load it directly with library functions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Inspect Data\n",
    "Start by inspecting the data. Write code to output the following: \n",
    "- The shape of the training data\n",
    "- The shape of the testing data\n",
    "- The total number of outputs\n",
    "- A lit of the output classes\n",
    "- Display the first image in the training data\n",
    "- Display the first image in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape : 47040000\n",
      "Testing data shape : 7840000\n",
      "Total number of outputs : 70000\n",
      "Output classes : [5, 0, 4, 1, 9, 2, 3, 6, 7, 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x288fe61f9c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### ======== YOUR CODE HERE ========== ###\n",
    "\n",
    "# Print shape of training data\n",
    "print('Training data shape : {}'.format(train_images.size))\n",
    " \n",
    "# Print shape of testing data    \n",
    "print('Testing data shape : {}'.format(test_images.size))\n",
    " \n",
    "# Print the total number of outputs\n",
    "print('Total number of outputs : {}'.format(train_labels.size+test_labels.size))\n",
    "\n",
    "# Print the list of output classes\n",
    "uni = []\n",
    "for lb in train_labels:\n",
    "    if lb not in uni:\n",
    "        uni.append(lb)\n",
    "    \n",
    "\n",
    "print('Output classes : {}'.format(uni))\n",
    " \n",
    "# Display the first image in the training data    \n",
    "\n",
    "plt.imshow(train_images[0], cmap = 'gray')\n",
    "    \n",
    "# Display the first image in the testing data  \n",
    "\n",
    "plt.imshow(test_images[0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Preprocess Data\n",
    "As usual, we need to preprocess our data. Write code to do the following:\n",
    "- Reshape the images from a 28x28 matrix to 784 flattend array (28x28=784), so it can be fed into the network as a single feature\n",
    "- Convert the datatype to 'float32' and then normalie the pixels so the values range between 0 and 1 (Hint: The current values range from 0 to 255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img size = 784, Img num = 47040000\n"
     ]
    }
   ],
   "source": [
    "### ======== YOUR CODE HERE ========== ###\n",
    "\n",
    "# Flatten the data to a 784 element array for both the train and test sets\n",
    "X_train = train_images.reshape(train_images.shape[0],784)\n",
    "\n",
    "X_test = test_images.reshape(test_images.shape[0],784)\n",
    "\n",
    "print('Img size = {}, Img num = {}'.format(X_train[0].size, X_train.size))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to data type to float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to a scale between 0 and 1\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Convert Labels \n",
    "Conver the labels from integer to categorical (one-hot encoding). We have to do this conversion, because that is the format required by Keras to perform multiclass classification. One-hot encoding converts the integer to an array of all zeros except a 1 at the index of the integer.\n",
    "\n",
    "For example, using a one-hot encoding for 10 classes, the integer 5 will be encoded as 0000010000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ======== YOUR CODE HERE ========== ###\n",
    "# Change the labels from integer to categorical data and store this in a new variable \n",
    "# (Hint: Use the to_categorical function in keras)\n",
    "\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the original and converted labels the item in the dataset\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Create model\n",
    "\n",
    "Create a sequential model with the following architecture:\n",
    "- an input dense layer of 512 units using the ReLU activation function, with input dimension of 784\n",
    "- a dense layer of 512 units with the ReLU activation function\n",
    "- a output layer of 10 units with the softmax activation function (output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell to get rid of some warnings later on\n",
    "\n",
    "def noWarnings():\n",
    "    import os\n",
    "    os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '0'\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "    from tensorflow import logging\n",
    "    logging.set_verbosity(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ======== YOUR CODE HERE ========== ###\n",
    "\n",
    "# Create sequential model\n",
    "noWarnings()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape = (784,),activation = 'relu'))\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 - Compile Model\n",
    "\n",
    "Compile the model with an **rmsprop optimizer, categorical_crossentropy loss, and accuracy metrics**. You can try other optimizers too such as sgd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 - Train model\n",
    "Fit the model and train for **20 epochs** and a **batch size of 256**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.2638 - acc: 0.9241\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0919 - acc: 0.9730\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0579 - acc: 0.9820\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0397 - acc: 0.9880: 0s - loss: 0.0\n",
      "Epoch 5/20\n",
      "50944/60000 [========================>.....] - ETA: 0s - loss: 0.0285 - acc: 0.9913"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-25f36cf834f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./stuff.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\bp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, verbose=True, epochs=20, batch_size = 256)\n",
    "model.save('./stuff.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ======== YOUR CODE HERE ========== ###\n",
    "from keras.models import load_model\n",
    "#Load model\n",
    "model = load_model('.\\stuff.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 - Evaluate model\n",
    "Report the loss and accuracy on the test data. (Hint: Use the built in *model.evaluate* function in keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 66us/step\n",
      "Test loss: 0.11497843549760864\n",
      "Test accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "### ======== YOUR CODE HERE ========== ###\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Report loss and accuracy on test data\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9 - Plot results\n",
    "- Plot the loss curves for both training and validation\n",
    "- Plot the accuracy curves for both training and validation\n",
    "\n",
    "Hint: Use the *.history* function to access these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x258d3f14d48>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### ======== YOUR CODE HERE ========== ###\n",
    "\n",
    "# Plot the Loss Curves\n",
    "\n",
    "plt.plot(history.history['loss'])    \n",
    "     \n",
    "# Plot the Accuracy Curves\n",
    "plt.plot(history.history['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 - Regularization\n",
    "If done properly, you will notice there is some overfitting in the model. To overcome this, we will use a regularization method called **dropout** which you will learn in the CNN lecture. This requires simply adding dropout layers into our model. To do so, repeat steps 5-8 with the following architecture.\n",
    "- an input dense layer of 512 units using the ReLU activation function, with input dimension of 784\n",
    "- a dropout layer with 0.5 dropout rate\n",
    "- a dense layer of 512 units with the ReLU activation function\n",
    "- a dropout layer with 0.5 dropout rate\n",
    "- a output layer of 10 units with the softmax activation function (output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ======== YOUR CODE HERE ========== ###\n",
    "\n",
    "# Repeat step 5 with new architecture\n",
    "new_model = Sequential()\n",
    "new_model.add(Dense(512,input_shape = (784,), activation = 'relu'))\n",
    "new_model.add(Dropout(0.5))\n",
    "new_model.add(Dense(512, activation = 'relu'))\n",
    "new_model.add(Dropout(0.5))\n",
    "new_model.add(Dense(10, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat step 6 with new model\n",
    "new_model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.4028 - acc: 0.8763\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1707 - acc: 0.9477\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1306 - acc: 0.9608: 0s - loss: 0.1307 - acc: 0.\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1077 - acc: 0.9657\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0922 - acc: 0.9710\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.0845 - acc: 0.9732\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0747 - acc: 0.9769\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0693 - acc: 0.9787\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0643 - acc: 0.9786\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0591 - acc: 0.9812\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0554 - acc: 0.9824\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0539 - acc: 0.9826\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0532 - acc: 0.9826\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0492 - acc: 0.9845\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0471 - acc: 0.9850\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0448 - acc: 0.9850\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0440 - acc: 0.9856\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0403 - acc: 0.9866\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0414 - acc: 0.9863\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0374 - acc: 0.9881\n"
     ]
    }
   ],
   "source": [
    "# Repeat step 7 with new model\n",
    "history = new_model.fit(X_train, y_train, verbose=True, epochs=20, batch_size = 256)\n",
    "model.save('./new_stuff.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 80us/step\n",
      "Test loss: 0.058619084055074926\n",
      "Test accuracy: 0.9841\n"
     ]
    }
   ],
   "source": [
    "# Repeat step 8 with new model\n",
    "### ======== YOUR CODE HERE ========== ###\n",
    "\n",
    "loss, acc = new_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Report loss and accuracy on test data\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x258ef5427c8>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Repeat step 9 with new model\n",
    "### ======== YOUR CODE HERE ========== ###\n",
    "\n",
    "# Plot the Loss Curves\n",
    "\n",
    "plt.plot(history.history['loss'])    \n",
    "     \n",
    "# Plot the Accuracy Curves\n",
    "plt.plot(history.history['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BONUS QUESTION - Modified MNIST\n",
    "The modified MNIST dataset consists of images that contain multiple written digits with background noise. The labels for this dataset is the largest digit contained in the image. Your challenge will be to train a feed forward network to predict these labels. You can follow the same steps as in this assignment to create the feed forward neural network, but you will likely have to experiment with different data preprocessing techniques and network structures. You will also need to load the dataset yourself and put it into a form that is acceptable by keras.\n",
    "\n",
    "The dataset can be downloaded from (https://techx.blob.core.windows.net/modified-mnist/modified-mnist.zip)[here]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
